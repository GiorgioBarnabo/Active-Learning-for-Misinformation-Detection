
method: random

data_params:
    +dataname:
        - gossipcop
        - politifact
        - condor #'twitter' #condor_gossipcop_politifact #condor #gossipcop #politifact
    warm_start_years: [inf,inf] #warm-start data from year[0] (included) to year[1] (included)
                                #to avoid warm-start: pick np.inf
    training_years: [2005,2021] #to train (after warm-start) from year[0] (included) to year[1] (included)
    train_val_test_split_ratio: [0.80, 0.10, 0.10]
    batch_size: 128

model_params:
    epochs: 30 #35 graph_model
    graph_test_size: 0.25 #because is not divided --> change if split data
    graph_feature: bert #profile, spacy, bert, content
    +graph_model_name: 
        - gat
        - gcn
        - sage
    #model_type = "time" #time #graph

experiment_params:
    starting_seed: 123
    nb_samples: 1
    results_set: RNN_GNN

AL_params:
    offline_AL: 30 #0 == Online, >0 == Number of iterations for Offline AL
    +AL_method:
        - random
        - uncertainty-margin
        #["combined", "uncertainty-margin", "diversity-cluster", "random"] #don't use "_" to keep filename easily separable
    #+num_urls_k: ??? #overrides tot_num_checked_urls if set
    tot_num_checked_urls: 1200
    #diversity_nums: [1,1,1] #centroids, outliers, randoms; used only if AL_method = diversity-cluster
    #combined_AL_nums: [1,7,2] #ignored if AL_method is not "combined" #random, uncertainty, diversity

    train_last_samples: inf #Use np.inf to not discard training 
    val_last_samples: inf #Use np.inf to not discard validation
    add_val_to_train: False #(discard=add to train)
    retrain_from_scratch: True